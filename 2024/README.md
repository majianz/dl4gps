# 2024

1. \[LANS] **LANS: A Layout-Aware Neural Solver for Plane Geometry Problem**, Findings of ACL 2024 \[[paper](https://aclanthology.org/2024.findings-acl.153/)]

2. \[GeomVerse] **GeomVerse: A Systematic Evaluation of Large Models for Geometric Reasoning**, ICML 2024 AI4MATH Workshop \[[paper](https://openreview.net/forum?id=1AUbiBrOF1)]

3. \[AlphaGeometry] **Solving Olympiad Geometry Without Human Demonstrations**, Nature 2024 \[[paper](https://www.nature.com/articles/s41586-023-06747-5)]

4. \[GAPS] **GAPS: Geometry-Aware Problem Solver**, arXiv:2401.16287 \[[paper](https://arxiv.org/abs/2401.16287)]

5. \[E-GPS] **E-GPS: Explainable Geometry Problem Solving via Top-Down Solver and Bottom-Up Generator**, CVPR 2024 \[[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wu_E-GPS_Explainable_Geometry_Problem_Solving_via_Top-Down_Solver_and_Bottom-Up_CVPR_2024_paper.html)]

6. \[Multi-Agent Framework/Euclidea] **Beyond Lines and Circles Unveiling the Geometric Reasoning Gap in Large Language Models**, Findings of EMNLP 2024 \[[paper](https://aclanthology.org/2024.findings-emnlp.360/)] :small_red_triangle:

7. \[FGeo-TP] **FGeo-TP: A Language Model-Enhanced Solver for Geometry Problems**, Symmetry 2024 \[[paper](https://www.mdpi.com/2073-8994/16/4/421)]

8. \[FGeo-DRL] **FGeo-DRL: Deductive Reasoning for Geometric Problems Through Deep Reinforcement Learning**, Symmetry 2024 \[[paper](https://www.mdpi.com/2073-8994/16/4/437)]

9. \[FGeo-SSS] **FGeo-SSS: A Search-Based Symbolic Solver for Human-Like Automated Geometric Reasoning**, Symmetry 2024 \[[paper](https://www.mdpi.com/2073-8994/16/4/404)] \:x:

10. \[FGeo-HyperGNet] **FGeo-HyperGNet: Geometric Problem Solving Integrating Formal Symbolic System and Hypergraph Neural Network**, arXiv:2402.11461 \[[paper](https://arxiv.org/abs/2402.11461)]

11. \[OlympiadBench] **OlympiadBench: A Challenging Benchmark for Promoting AGI With Olympiad-Level Bilingual Multimodal Scientific Problems**, ACL 2024 \[[paper](https://aclanthology.org/2024.acl-long.211/)] \:large\_blue\_circle:

12. \[MathVista] **MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts**, ICLR 2024 \[[paper](https://iclr.cc/virtual/2024/oral/19768)] \:large\_blue\_circle:

13. \[MathVerse] **MathVerse: Does Your Multi-Modal LLM Truly See the Diagrams in Visual Math Problems?**, ECCV 2024 \[[paper](https://dl.acm.org/doi/10.1007/978-3-031-73242-3_10)] \:large\_blue\_circle:

14. \[MATH-Vision] **Measuring Multimodal Mathematical Reasoning With MATH-Vision Dataset**, NeurIPS 2024 \[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/ad0edc7d5fa1a783f063646968b7315b-Abstract-Datasets_and_Benchmarks_Track.html)] \:large\_blue\_circle:

15. \[MM-MATH] **MM-MATH: Advancing Multimodal Math Evaluation With Process Evaluation and Fine-Grained Classification**, Findings of EMNLP 2024 \[[paper](https://aclanthology.org/2024.findings-emnlp.73/)] \:large\_blue\_circle:

16. \[Wu+AlphaGeometry] **Wu’s Method Boosts Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry**, NeurIPS 2024 MATH-AI Workshop \[[paper](https://openreview.net/forum?id=aKRtC45gle)]

17. \[GOLD] **GOLD: Geometry Problem Solver With Natural Language Description**, Findings of NAACL 2024 \[[paper](https://aclanthology.org/2024.findings-naacl.19/)]

18. \[DualGeoSolver] **Learning to Solve Geometry Problems via Simulating Human Dual-Reasoning Process**, IJCAI 2024 \[[paper](https://www.ijcai.org/proceedings/2024/0725.pdf)]

19. \[Autoformalization/LeanEuclid] **Autoformalizing Euclidean Geometry**, ICML 2024 \[[paper](https://dl.acm.org/doi/abs/10.5555/3692070.3693567)] :small_red_triangle:

20. \[GeoEval] **GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on Geometry Problem-Solving**, Findings of ACL 2024 \[[paper](https://aclanthology.org/2024.findings-acl.73/)]

21. \[GeoGPT4V] **GeoGPT4V: Towards Geometric Multi-Modal Large Language Models With Geometric Image Generation**, EMNLP 2024 \[[paper](https://aclanthology.org/2024.emnlp-main.44/)]

22. \[Different Modalities Evaluation] **Figuring Figures: An Assessment of Large Language Models on Different Modalities of Math Word Problems**, ICMLT 2024 \[[paper](https://dl.acm.org/doi/abs/10.1145/3674029.3674041)]

23. \[Math-LLaVA/MathV360K] **Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models**, EMNLP Findings 2024 \[[paper](https://aclanthology.org/2024.findings-emnlp.268/)] \:large\_blue\_circle:

24. \[We-Math] **We-Math: Does Your Large Multimodal Model Achieve Human-Like Mathematical Reasoning?**, arXiv:2407.01284 \[[paper](https://arxiv.org/abs/2407.01284)] \:large\_blue\_circle:

25. \[PGPSNet-v2] **Fuse, Reason and Verify: Geometry Problem Solving With Parsed Clauses From Diagram**, arXiv:2407.07327 \[[paper](https://arxiv.org/abs/2407.07327)]

26. \[MATHCHECK/MATHCHECK-GEO] **Is Your Model Really a Good Math Reasoner? Evaluating Mathematical Reasoning With Checklist**, arXiv:2407.08733 \[[paper](https://arxiv.org/abs/2407.08733)]

27. \[HGR] **Hologram Reasoning for Solving Algebra Problems With Geometry Diagrams**, arXiv:2408.10592 \[[paper](https://arxiv.org/abs/2408.10592)]

28. \[EAGLE] **EAGLE: Elevating Geometric Reasoning Through LLM-Empowered Visual Instruction Tuning**, arXiv:2408.11397 \[[paper](https://arxiv.org/abs/2408.11397)]

29. \[Tangram] **Tangram: A Challenging Benchmark for Geometric Element Recognizing**, arXiv:2408.13854 \[[paper](https://arxiv.org/abs/2408.13854)]

30. \[GeoCQT/2DGeoShapeNet] **Leveraging Two-Level Deep Learning Classifers for 2D Shape Recognition to Automatically Solve Geometry Math Word Problems**, PAA 2024 \[[paper](https://link.springer.com/article/10.1007/s10044-024-01321-9)]

31. \[MultiMath/MultiMath-300K] **MultiMath: Bridging Visual and Mathematical Reasoning for Large Language Models**, arXiv:2409.00147 \[[paper](https://arxiv.org/abs/2409.00147)] \:large\_blue\_circle:

32. \[InfiMM-WebMath-40B] **InfiMM-WebMath-40B: Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning**, NeurIPS 2024 MATH-AI Workshop \[[paper](https://openreview.net/forum?id=Twzrpa6V2o)] \:large\_blue\_circle:

33. \[MathGLM-Vision/MathVL] **MathGLM-Vision: Solving Mathematical Problems With Multi-Modal Large Language Model**, arXiv:2409.13729 \[[paper](https://arxiv.org/abs/2409.13729)] \:large\_blue\_circle:

34. \[ATB-NGS] **Enhancing Geometry Problem Solving With Attention Mechanism and Super-Resolution**, ICBASE 2024 \[[paper](https://ieeexplore.ieee.org/abstract/document/10762589)]

35. \[Point Geometry Identity/Proof Problems Generation] **Automated Generation of Geometry Proof Problems Based on Point Geometry Identity**, Journal of Automated Reasoning 2024 \[[paper](https://link.springer.com/article/10.1007/s10817-024-09699-1)] \:x:

36. \[Geo-Qwen] **Geo-Qwen: A Geometry Problem-Solving Method Based on Generative Large Language Models and Heuristic Reasoning**, ICCWAMTIP 2024 \[[paper](https://ieeexplore.ieee.org/abstract/document/10873683)]

37. \[formalgeo7k/FormalGeo] **Formal Representation and Solution of Plane Geometric Problems**, NeurIPS 2024 MATH-AI Workshop \[[paper](https://openreview.net/forum?id=8wDSfs1W3w)]

38. \[GeoVQA] **GeoVQA: A Comprehensive Multimodal Geometry Dataset for Secondary Education**, MIPR 2024 \[[paper](https://ieeexplore.ieee.org/abstract/document/10707789)]

39. \[Geo-LLaVA/GeoMath] **Geo-LLaVA: A Large Multi-Modal Model for Solving Geometry Math Problems With Meta In-Context Learning**, LGM3A 2024 \[[paper](https://dl.acm.org/doi/10.1145/3688866.3689124)]

40. \[R\&E] **Reason-and-Execute Prompting: Enhancing Multi-Modal Large Language Models for Solving Geometry Questions**, MM 2024 \[[paper](https://dl.acm.org/doi/abs/10.1145/3664647.3681484)]

41. \[R-CoT] **R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models**, arXiv:2410.17885 \[[paper](https://arxiv.org/abs/2410.17885)]

42. \[LLaVA-CoT] **LLaVA-o1: Let Vision Language Models Reason Step-by-Step**, arXiv:2411.10440 \[[paper](https://arxiv.org/abs/2411.10440)] \:large\_blue\_circle:

43. \[R3V/VLM Reflection] **Vision-Language Models Can Self-Improve Reasoning via Reflection**, arXiv:2411.00855 \[[paper](https://arxiv.org/abs/2411.00855)] \:large\_blue\_circle:

44. \[DenseNet] **A Geometric Neural Solving Method Based on a Diagram Text Information Fusion Analysis**, Sci. Rep. 2024 \[[paper](https://www.nature.com/articles/s41598-024-83287-6)]

45. \[SP-1] **Slow Perception: Let's Perceive Geometric Figures Step-by-Step**, arXiv:2412.20631 \[[paper](https://arxiv.org/abs/2412.20631)]

46. \[MATHS/MNS] **Maths: Multimodal Transformer-Based Human-Readable Solver**, ICME 2024 \[[paper](https://ieeexplore.ieee.org/abstract/document/10687434)]

47. \[METEOR/ElementaryGeometryQA] **Automatic Extraction of Structured Information from Elementary Level Geometry Questions into Logic Forms**, Multimed Tools Appl 2024 \[[paper](https://link.springer.com/article/10.1007/s11042-024-20463-w)]

48. \[GPSM4K/RAG] **Improving Multimodal LLMs Ability in Geometry Problem Solving, Reasoning, and Multistep Scoring**, arXiv:2412.00846 \[[paper](https://arxiv.org/abs/2412.00846)]

49. \[GPSM4K] **Advancing Multimodal LLMs: A Focus on Geometry Problem Solving Reasoning and Sequential Scoring**, MMASIA 2024 \[[paper](https://dl.acm.org/doi/full/10.1145/3696409.3700262)]

50. \[SKETCHPAD] **Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models**, NeurIPS 2024 \[[paper](https://openreview.net/forum?id=GNSMl1P5VR)] \:large\_blue\_circle:

51. \[2D Shape Detection] **2D Shape Detection for Solving Geometry Word Problems**, IETE J. Res. 2024 \[[paper](https://www.tandfonline.com/doi/abs/10.1080/03772063.2023.2274914)] \:x:

52. \[VisAidMath] **VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning**, arXiv:2410.22995 \[[paper](https://arxiv.org/abs/2410.22995)] \:large\_blue\_circle:

53. \[Euclid/Geoperception] **Euclid: Supercharging Multimodal LLMs With Synthetic High-Fidelity Visual Descriptions**, arXiv:2412.08737 \[[paper](https://arxiv.org/abs/2412.08737)]

54. \[AtomThink] **AtomThink: A Slow Thinking Framework for Multimodal Mathematical Reasoning**, arXiv:2411.11930 \[[paper](https://arxiv.org/abs/2411.11930)] \:large\_blue\_circle:

55. \[Mulberry] **Mulberry: Empowering MLLM With o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search**, arXiv:2412.18319 \[[paper](https://arxiv.org/abs/2412.18319)] \:large\_blue\_circle:

56. \[Dataset Evaluation] **What is the True Performance of Large Multimodal Models in Visual Context-Based Mathematical Reasoning? An Analysis of Multiple Datasets and Future Research Directions**, ICTC 2024 \[[paper](https://ieeexplore.ieee.org/abstract/document/10827294)]

57. \[GePBench] **GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models**, arXiv:2412.21036 \[[paper](https://arxiv.org/abs/2412.21036)]

58. \[DrawEduMath] **DrawEduMath: Evaluating Vision Language Models with Expert-Annotated Students’ Hand-Drawn Math Images**, NeurIPS 2024 MATH-AI Workshop \[[paper](https://openreview.net/forum?id=0vQYvcinij)] \:large\_blue\_circle:

59. \[Number Line Problems] **An Enhanced Relation-Flow Algorithm for Solving Number Line Problems**, IEIR 2024 \[[paper](https://ieeexplore.ieee.org/abstract/document/10960042)] \:x:

60. \[VCAR/Describe-then-Reason] **Describe-then-Reason: Improving Multimodal Mathematical Reasoning Through Visual Comprehension Training**, arXiv:2404.14604 \[[paper](https://arxiv.org/abs/2404.14604)] \:large\_blue\_circle:

61. \[Vision-Augmented Prompting/BIG-bench-IG]
    **Enhancing LLM Reasoning via Vision-Augmented Prompting**, NeurIPS 2024
    \[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/328c922d068dd4ccb23cec5c64e6c7fc-Abstract-Conference.html)]

62. \[Formal Language Generation]
    **Evaluating Automated Geometric Problem Solving With Formal Language Generation on Large Multimodal Models**, IEIR 2024
    \[[paper](https://ieeexplore.ieee.org/abstract/document/10959992)]

63. \[MS-CoT]
    **Multi-Step Chain-of-Thought in Geometry Problem Solving**, EIECS 2024
    \[[paper](https://ieeexplore.ieee.org/abstract/document/10800087)]

64. \[VisOnlyQA/VisOnlyQA-Geometry]
    **VisOnlyQA: Large Vision Language Models Still Struggle With Visual Perception of Geometric Information**, arXiv:2412.00947
    \[[paper](https://arxiv.org/abs/2412.00947)] \:large\_blue\_circle:

65. \[CMM-Math]
    **CMM-Math: A Chinese Multimodal Math Dataset to Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models**, arXiv:2409.02834
    \[[paper](https://arxiv.org/abs/2409.02834)] \:large\_blue\_circle:

66. \[I2L]
    **All in an Aggregated Image for In-Image Learning**, arXiv:2402.17971
    \[[paper](https://arxiv.org/abs/2402.17971)] \:large\_blue\_circle:

67. \[CurveML]
    **CurveML: A Benchmark for Evaluating and Training Learning-Based Methods of Classification, Recognition, and Fitting of Plane Curves**, Visual Comput 2024
    \[[paper](https://link.springer.com/article/10.1007/s00371-024-03292-8)]

68. \[ArXivQA]
    **Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models**, ACL 2024
    \[[paper](https://aclanthology.org/2024.acl-long.775/)] \:large\_blue\_circle:

69. \[MathScape]
    **MathScape: Evaluating MLLMs in Multimodal Math Scenarios Through a Hierarchical Benchmark**, arXiv:2408.07543
    \[[paper](https://arxiv.org/abs/2408.07543)] \:large\_blue\_circle:

70. \[VisScience]
    **VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-Modal Scientific Reasoning**, arXiv:2409.13730
    \[[paper](https://arxiv.org/abs/2409.13730)] \:large\_blue\_circle:

71. \[AR-MCTS]
    **Progressive Multimodal Reasoning via Active Retrieval**, arXiv:2412.14835
    \[[paper](https://arxiv.org/abs/2412.14835)] \:large\_blue\_circle:

72. \[AVSBench]
    **Decomposing Complex Visual Comprehension Into Atomic Visual Skills for Vision Language Models**, NeurIPS 2024 MATH-AI Workshop
    \[[paper](https://openreview.net/forum?id=nFU4xCyoe0)] \:large\_blue\_circle:

73. \[ReMI]
    **ReMI: A Dataset for Reasoning With Multiple Images**, NeurIPS 2024
    \[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/6ea56c0baacac9f7764257a43a93c90a-Abstract-Datasets_and_Benchmarks_Track.html)] \:large\_blue\_circle:

74. \[M3GIA]
    **M3GIA: A Cognition-Inspired Multilingual and Multimodal General Intelligence Ability Benchmark**, arXiv:2406.05343
    \[[paper](https://arxiv.org/abs/2406.05343)] \:large\_blue\_circle:

75. \[ArMATH]
    **Mathematical Problem Solving in Arabic: Assessing Large Language Models**, Procedia Computer Science 2024
    \[[paper](https://www.sciencedirect.com/science/article/pii/S187705092402982X)] \:large\_blue\_circle:

76. \[M3CoT]
    **M3CoT: A Novel Benchmark for Multi-Domain Multi-Step Multi-Modal Chain-of-Thought**, ACL 2024
    \[[paper](https://aclanthology.org/2024.acl-long.446/)] \:large\_blue\_circle:

77. \[MathOdyssey]
    **MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data**, arXiv:2406.18321
    \[[paper](https://arxiv.org/abs/2406.18321)] \:large\_blue\_circle:

78. \[PutnamBench]
    **PutnamBench: Evaluating Neural Theorem-Provers on the Putnam Mathematical Competition**, NeurIPS 2024
    \[[paper](https://openreview.net/forum?id=ChKCF75Ocd)] \:large\_blue\_circle:

79. \[FAULTYMATH]
    **From Blind Solvers to Logical Thinkers: Benchmarking LLMs’ Logical Integrity on Faulty Mathematical Problems**, arXiv:2410.18921
    \[[paper](https://arxiv.org/abs/2410.18921)] \:large\_blue\_circle:

80. \[ConceptMath]
    **ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models**, Findings of ACL 2024
    \[[paper](https://aclanthology.org/2024.findings-acl.407/)] \:large\_blue\_circle:

81. \[MATH()]
    **Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap**, arXiv:2402.19450
    \[[paper](https://arxiv.org/abs/2402.19450)] \:large\_blue\_circle:

82. \[MathBench]
    **MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark**, Findings of ACL 2024
    \[[paper](https://aclanthology.org/2024.findings-acl.411/)] \:large\_blue\_circle:

83. \[HARP]
    **HARP: A Challenging Human-Annotated Math Reasoning Benchmark**, arXiv:2412.08819
    \[[paper](https://arxiv.org/abs/2412.08819)] \:large\_blue\_circle:

84. \[PHP]
    **Progressive-Hint Prompting Improves Reasoning in Large Language Models**, ICML 2024 AI4MATH Workshop
    \[[paper](https://openreview.net/forum?id=UkFEs3ciz8)] \:large\_blue\_circle:

85. \[Learning to Plan]
    **Learning to Plan by Updating Natural Language**, Findings of EMNLP 2024
    \[[paper](https://aclanthology.org/2024.findings-emnlp.589/)] \:large\_blue\_circle:

86. \[Reprompting]
    **Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling**, ICML 2024
    \[[paper](https://proceedings.mlr.press/v235/xu24b.html)] \:large\_blue\_circle:

87. \[SKiC]
    **Skills-in-Context: Unlocking Compositionality in Large Language Models**, Findings of EMNLP 2024
    \[[paper](https://aclanthology.org/2024.findings-emnlp.812/)] \:large\_blue\_circle:

88. \[TORA]
    **ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving**, ICLR 2024
    \[[paper](https://openreview.net/forum?id=Ep0TtjVoap)] \:large\_blue\_circle:

89. \[GAI for Spanish]
    **Can Generative AI Solve Geometry Problems? Strengths and Weaknesses of LLMs for Geometric Reasoning in Spanish**, IJIMAI 2024
    \[[paper](https://dialnet.unirioja.es/servlet/articulo?codigo=9906100)]

90. \[EM²]
    **Explicit Memory Learning with Expectation Maximization**, EMNLP 2024
    \[[paper](https://aclanthology.org/2024.emnlp-main.927.pdf)] \:large\_blue\_circle:

91. \[MathSensei/PoT for geometry problem]
    **MathSensei: Mathematical Reasoning with a Tool-Augmented Large Language Model**, ICLR 2024 ME-FoMo Workshop
    \[[paper](https://openreview.net/forum?id=YDQ6eBB4py)] \:large\_blue\_circle:

92. \[Null-Shot Prompting with CoT]
    **Null-Shot Prompting: Rethinking Prompting Large Language Models With Hallucination**, EMNLP 2024
    \[[paper](https://aclanthology.org/2024.emnlp-main.740/)] \:large\_blue\_circle:

93. \[StrategyLLM]
    **Strategyllm: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving**, NeurIPS 2024
    \[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/af7cc9e2366b8f8837a6ef339810277a-Abstract-Conference.html)] \:large\_blue\_circle:

94. \[BBA]
    **BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models**, Findings of ACL 2024
    \[[paper](https://aclanthology.org/2024.findings-acl.433/)]

95. \[HSP]
    **Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge**, arXiv:2402.14310
    \[[paper](https://arxiv.org/abs/2402.14310)] \:large\_blue\_circle:

96. \[MathScale]
    **MathScale: Scaling Instruction Tuning for Mathematical Reasoning**, ICML 2024
    \[[paper](https://proceedings.mlr.press/v235/tang24k.html)] \:large\_blue\_circle:

97. \[LECO]
    **Learning From Correctness Without Prompting Makes LLM Efficient Reasoner**, COLM 2024
    \[[paper](https://openreview.net/forum?id=dcbNzhVVQj)] \:large\_blue\_circle:

98. \[MACM]
    **MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems**, NeurIPS 2024
    \[[paper](https://openreview.net/forum?id=VR2RdSxtzs)] \:large\_blue\_circle:

99. \[FUNCODER]
     **Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation**, NeurIPS 2024
     \[[paper](https://openreview.net/forum?id=cFqAANINgW)] \:large\_blue\_circle:

100. \[SWAP]
     **Deliberate Reasoning for LLMs as Structure-Aware Planning with Accurate World Model**, arXiv:2410.03136
     \[[paper](https://arxiv.org/abs/2410.03136)] \:large\_blue\_circle:

101. \[Hinting]
     **Give me a Hint: Can LLMs Take a Hint to Solve Math Problems?**, NeurIPS 2024 MATH-AI Workshop
     \[[paper](https://openreview.net/forum?id=eeZG97VjYa)] \:large\_blue\_circle:

102. \[MC-NEST]
     **MC-NEST--Enhancing Mathematical Reasoning in Large Language Models with a Monte Carlo Nash Equilibrium Self-Refine Tree**, arXiv:2411.15645
     \[[paper](https://arxiv.org/abs/2411.15645)] \:large\_blue\_circle:

103. \[DART-Math]
     **DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving**, NeurIPS 2024
     \[[paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/0ef1afa0daa888d695dcd5e9513bafa3-Abstract-Conference.html)] \:large\_blue\_circle:

104. \[AgentOptimizer]
     **Offline Training of Language Model Agents with Functions as Learnable Weights**, ICML 2024
     \[[paper](https://proceedings.mlr.press/v235/zhang24cd.html)] \:large\_blue\_circle:

105. \[UTMath]
     **UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts**, arXiv:2411.07240
     \[[paper](https://arxiv.org/abs/2411.07240)] \:large\_blue\_circle:

106. \[MultiLingPoT]
     **MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning**, arXiv:2412.12609
     \[[paper](https://arxiv.org/abs/2412.12609)] \:large\_blue\_circle:

107. \[EIT]
     **System-2 Mathematical Reasoning via Enriched Instruction Tuning**, arXiv:2412.16964
     \[[paper](https://arxiv.org/abs/2412.16964)] \:large\_blue\_circle:

108. \[Beyond Captioning]
     **Beyond Captioning: Task-Specific Prompting for Improved VLM Performance in Mathematical Reasoning**, arXiv:2410.05928
     \[[paper](https://arxiv.org/abs/2410.05928)]
